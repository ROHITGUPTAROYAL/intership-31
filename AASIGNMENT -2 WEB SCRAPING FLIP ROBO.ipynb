{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96af87de",
   "metadata": {},
   "source": [
    "# Q1-Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ffdded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\rohit gupta\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8044e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7e0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohit Gupta\\Desktop\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b47742",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10734f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0510502",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73635750",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6f309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store data the scraped data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping job experience from the given page\n",
    "experince_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experince_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b5853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(company_name),len(experience_required),len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "714ae1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>com_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>exprerince_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL hiring For Data Analyst</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Programmer / Data Analyst</td>\n",
       "      <td>Frost &amp; Sullivan</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - Python/Artificial Intelligence</td>\n",
       "      <td>iMindYourBusiness</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Data Analyst</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - Decision Science</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Immediate opening For Data Analyst @ Bangalore</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Optum</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Optum</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                        HCL hiring For Data Analyst   \n",
       "2                          Programmer / Data Analyst   \n",
       "3      Data Analyst - Python/Artificial Intelligence   \n",
       "4                              Customer Data Analyst   \n",
       "5                                   Sr. Data Analyst   \n",
       "6                    Data Analyst - Decision Science   \n",
       "7     Immediate opening For Data Analyst @ Bangalore   \n",
       "8                             Associate Data Analyst   \n",
       "9                             Associate Data Analyst   \n",
       "\n",
       "                                  com_name  \\\n",
       "0                                TeamLease   \n",
       "1                         HCL Technologies   \n",
       "2                         Frost & Sullivan   \n",
       "3                        iMindYourBusiness   \n",
       "4                                   Oracle   \n",
       "5  Global Indian School Education Services   \n",
       "6                  Jana Small Finance Bank   \n",
       "7                                TeamLease   \n",
       "8                                    Optum   \n",
       "9                                    Optum   \n",
       "\n",
       "                                        job_location exprerince_required  \n",
       "0                                Bangalore/Bengaluru             5-8 Yrs  \n",
       "1                 Bangalore/Bengaluru, Pune, Chennai             3-8 Yrs  \n",
       "2  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...             3-7 Yrs  \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...             0-2 Yrs  \n",
       "4                                Bangalore/Bengaluru             1-3 Yrs  \n",
       "5                          Bangalore/Bengaluru, Pune            6-11 Yrs  \n",
       "6                                Bangalore/Bengaluru             3-8 Yrs  \n",
       "7                                Bangalore/Bengaluru             4-6 Yrs  \n",
       "8                                Bangalore/Bengaluru             2-7 Yrs  \n",
       "9                                Bangalore/Bengaluru             1-4 Yrs  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the data frame from above data\n",
    "df=pd.DataFrame({'job_title':job_title,'com_name':company_name,'job_location':job_location,'exprerince_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ff9da",
   "metadata": {},
   "source": [
    "# Q2-Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9898d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohit Gupta\\Desktop\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4710d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b1fd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "nation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11c46695",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a196cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43d0cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store data the scraped data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "\n",
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73e18783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(company_name),len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b57041b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>com_name</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>ZS Associates India Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Nagpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                       Data Scientist/AIML Engineer   \n",
       "5                            Data Science Consultant   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                                  Lead ML Scientist   \n",
       "\n",
       "                                      com_name  \\\n",
       "0                                Tech Mahindra   \n",
       "1                                   CitiusTech   \n",
       "2                                    Accenture   \n",
       "3  NTT DATA Business Solutions Private Limited   \n",
       "4                                       upGrad   \n",
       "5                  ZS Associates India Pvt Ltd   \n",
       "6                                  GlobalLogic   \n",
       "7                                  GlobalLogic   \n",
       "8                     TRH Consultancy Services   \n",
       "9                            Fractal Analytics   \n",
       "\n",
       "                                        job_location  \n",
       "0  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...  \n",
       "1                  Bangalore/Bengaluru, Mumbai, Pune  \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...  \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...  \n",
       "4  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...  \n",
       "5        Bangalore/Bengaluru, Pune, Gurgaon/Gurugram  \n",
       "6                 Bangalore/Bengaluru, Noida, Nagpur  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8  Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...  \n",
       "9                        Bangalore/Bengaluru, Mumbai  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the data frame from above data\n",
    "df=pd.DataFrame({'job_title':job_title,'com_name':company_name,'job_location':job_location})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e17a11",
   "metadata": {},
   "source": [
    "# Q3-In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "ASSIGNMENT 2\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32ae4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohit Gupta\\Desktop\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "accc1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08c2d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7db712a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "329f23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e78bef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[13]/div[2]/div[2]/label/p/span[1]\")\n",
    "job_location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54108b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3c98fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store data the scraped data\n",
    "job_title = []\n",
    "job_location =[]\n",
    "company_name = []\n",
    "experience_required =[]\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "title_tags= driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# Scraping Job Location from the given page\n",
    "location_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# Scraping Company name from the given page\n",
    "company_tags= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# Scraping Job Experience from the given page\n",
    "experience_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f941ee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d8e30ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Hiring- Expertise in Data Scientist in ...</td>\n",
       "      <td>Delhi / NCR, Gurgaon/Gurugram, Bangalore/Benga...</td>\n",
       "      <td>CLARITY CONSULTING</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)\\n(WFH during Covid)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                     Data Scientist   \n",
       "1                    DigitalBCG GAMMA Data Scientist   \n",
       "2              Data Scientist - Predictive Analytics   \n",
       "3                                     Data Scientist   \n",
       "4                  Data Scientist - Engine Algorithm   \n",
       "5                Data Scientist / Chat-bot Developer   \n",
       "6  Urgent Hiring- Expertise in Data Scientist in ...   \n",
       "7                                Lead Data Scientist   \n",
       "8         Data Scientist For Healthcare Product team   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                 Noida, Nagpur, Bangalore/Bengaluru   \n",
       "1                     New Delhi, Bangalore/Bengaluru   \n",
       "2  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "5  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...   \n",
       "6  Delhi / NCR, Gurgaon/Gurugram, Bangalore/Benga...   \n",
       "7         Noida(Sector-59 Noida)\\n(WFH during Covid)   \n",
       "8          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "               Company_name Exp_required  \n",
       "0               GlobalLogic     8-10 Yrs  \n",
       "1   Boston Consulting Group      2-5 Yrs  \n",
       "2              Confidential      1-6 Yrs  \n",
       "3                     Optum      2-7 Yrs  \n",
       "4              Primo Hiring      1-3 Yrs  \n",
       "5              Big Seo Buzz      3-7 Yrs  \n",
       "6        CLARITY CONSULTING      3-8 Yrs  \n",
       "7   R Systems International     7-10 Yrs  \n",
       "8  SECUREKLOUD TECHNOLOGIES      2-7 Yrs  \n",
       "9            Feedback Infra      2-4 Yrs  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "df = pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb7c72",
   "metadata": {},
   "source": [
    "# Q4-Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced7993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohit Gupta\\Desktop\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b106b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "015deb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering product in search bar as required\n",
    "Sunglass = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "Sunglass.send_keys('Sunglasses')\n",
    "\n",
    "time.sleep(3)\n",
    "# Serching Item\n",
    "search_here = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_here.click()\n",
    "\n",
    "# Creating the empty list\n",
    "Brand_Quality = []\n",
    "Product_Desc = []\n",
    "Price_Total = []\n",
    "Discount = []\n",
    " \n",
    "time.sleep(3)\n",
    "\n",
    "#Scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')      \n",
    "    for i in brand_tags:\n",
    "        Brand_Quality.append(i.text)     \n",
    "        \n",
    "    Product_Desc_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')     \n",
    "    for i in Product_Desc_tags:\n",
    "        Product_Desc.append(i.text)    \n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "    for i in Price_tags:\n",
    "        Price_Total.append(i.text)\n",
    "        \n",
    "    Discount_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in Discount_tags:\n",
    "        Discount.append(i.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) \n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6cb0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand_Quality),len(Product_Desc),len(Price_Total),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ba3421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹359</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹711</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹359</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹519</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Gradient Butterfly Sunglasses (62)</td>\n",
       "      <td>₹559</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, UV Protection, Night Vision Sp...</td>\n",
       "      <td>₹189</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Gradient Butterfly Sunglasses (55)</td>\n",
       "      <td>₹559</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, Riding Glasses Sports, Wrap-around ...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                       Product_Desc Price  \\\n",
       "0         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹799   \n",
       "1   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...  ₹359   \n",
       "2   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)  ₹449   \n",
       "3    VINCENT CHASE  by Lenskart Polarized, UV Protection Wayfarer ...  ₹711   \n",
       "4   ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...  ₹359   \n",
       "..             ...                                                ...   ...   \n",
       "95       ROYAL SON  Polarized, UV Protection Retro Square Sunglass...  ₹519   \n",
       "96       ROYAL SON  UV Protection, Gradient Butterfly Sunglasses (62)  ₹559   \n",
       "97      LIZA ANGEL  Riding Glasses, UV Protection, Night Vision Sp...  ₹189   \n",
       "98       ROYAL SON  UV Protection, Gradient Butterfly Sunglasses (55)  ₹559   \n",
       "99  ROZZETTA CRAFT  Polarized, Riding Glasses Sports, Wrap-around ...  ₹449   \n",
       "\n",
       "   Discount  \n",
       "0   20% off  \n",
       "1   82% off  \n",
       "2   79% off  \n",
       "3   71% off  \n",
       "4   82% off  \n",
       "..      ...  \n",
       "95  74% off  \n",
       "96  72% off  \n",
       "97  62% off  \n",
       "98  72% off  \n",
       "99  77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the above data\n",
    "df = pd.DataFrame({'Brand':Brand_Quality[:100],'Product_Desc':Product_Desc[:100],'Price':Price_Total[:100],'Discount':Discount[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b522293d",
   "metadata": {},
   "source": [
    "# Q5-Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field .\n",
    "3. Then click the search button.\n",
    "You will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2314e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohit Gupta\\Desktop\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94b3e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/apple-iphone-11-white-64-gb/product-reviews/itmfc6a7091eb20b?pid=MOBFWQ6BVWVEH3XE&lid=LSTMOBFWQ6BVWVEH3XEMXQMLO&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ba87432",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_summary=[] \n",
    "full_review=[]          \n",
    "rating=[]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50f72248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the required details usig the other loops\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    \n",
    "    rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tag:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "    review_summary_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_summary_tag[0:40]:\n",
    "        review_summary.append(i.text)    \n",
    "    \n",
    "    full_review_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_review_tag[0:40]:\n",
    "        full_review.append(i.text)\n",
    "    \n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be516b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d46f02ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_list</th>\n",
       "      <th>Rating_list</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Aspire 3 Laptop AMD 3020e Dual-Core Proce...</td>\n",
       "      <td></td>\n",
       "      <td>24,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i5 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>55,008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6...</td>\n",
       "      <td></td>\n",
       "      <td>21,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...</td>\n",
       "      <td></td>\n",
       "      <td>25,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6...</td>\n",
       "      <td></td>\n",
       "      <td>29,374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i5 11th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>33,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell Latitude E5470 Intel Core i5 6t...</td>\n",
       "      <td></td>\n",
       "      <td>44,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" ...</td>\n",
       "      <td></td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP 14s, 12th Gen Intel Core i5 16GB RAM/512GB ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 14s, 5th Gen AMD Ryzen 3- 8GB RAM/512GB SSD...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title_list Rating_list job_location\n",
       "0  Acer Aspire 3 Laptop AMD 3020e Dual-Core Proce...                   24,990\n",
       "1  Lenovo IdeaPad Slim 3 Intel Core i5 12th Gen 1...                   55,008\n",
       "2  Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6...                   21,513\n",
       "3  ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...                   25,990\n",
       "4  Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6...                   29,374\n",
       "5  Lenovo IdeaPad Slim 5 Intel Core i5 11th Gen 1...                   33,990\n",
       "6  (Renewed) Dell Latitude E5470 Intel Core i5 6t...                   44,999\n",
       "7  Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" ...                   59,990\n",
       "8  HP 14s, 12th Gen Intel Core i5 16GB RAM/512GB ...                         \n",
       "9  HP 14s, 5th Gen AMD Ryzen 3- 8GB RAM/512GB SSD...                         "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=pd.DataFrame({'Rating':rating,'Review summary':review_summary,'Full review':full_review})\n",
    "df.drop(index=df.index[100:],inplace=True) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954c03da",
   "metadata": {},
   "source": [
    "# Q6-Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72bfb894",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohit Gupta\\Desktop\\chromedriver_win32 (1)\\chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0f2ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering product in search bar as required\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('Sneakers')\n",
    "\n",
    "time.sleep(3)\n",
    "# Serching Item\n",
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d2e3081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the empty list\n",
    "Brand_Sneakers = []\n",
    "Product_Desc = []\n",
    "Price = []\n",
    "Discount = []\n",
    "time.sleep(3)\n",
    "\n",
    "#Scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')      \n",
    "    for i in brand_tags:\n",
    "        Brand_Sneakers.append(i.text)     \n",
    "        \n",
    "    Product_Desc_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')     \n",
    "    for i in Product_Desc_tags:\n",
    "        Product_Desc.append(i.text)    \n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "    Discount_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in Discount_tags:\n",
    "        Discount.append(i.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) \n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d221cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 106 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand_Sneakers),len(Product_Desc),len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31bed0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SFR</td>\n",
       "      <td>CAMP DENVER Sneakers For Men</td>\n",
       "      <td>₹653</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAMPUS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,849</td>\n",
       "      <td>7% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹348</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹396</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CAMPUS</td>\n",
       "      <td>Men Stylish Sneakers Casual Shoes Sneakers For...</td>\n",
       "      <td>₹1,849</td>\n",
       "      <td>7% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Xtoon</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹424</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HOCKWOOD</td>\n",
       "      <td>Combo pack of 3 casual sneaker shoes for men S...</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Smash v2 Buck Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹329</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                       Product_Desc   Price  \\\n",
       "0        SFR                       CAMP DENVER Sneakers For Men    ₹653   \n",
       "1     CAMPUS                                   Sneakers For Men  ₹1,849   \n",
       "2     Shozie                                   Sneakers For Men    ₹348   \n",
       "3   Magnolia                                   Sneakers For Men    ₹396   \n",
       "4   HOTSTYLE  Lightweight Pack Of 1 Trendy Sneakers Sneakers...    ₹199   \n",
       "..       ...                                                ...     ...   \n",
       "95    CAMPUS  Men Stylish Sneakers Casual Shoes Sneakers For...  ₹1,849   \n",
       "96     Xtoon                                   Sneakers For Men    ₹424   \n",
       "97  HOCKWOOD  Combo pack of 3 casual sneaker shoes for men S...    ₹799   \n",
       "98    BRUTON                     Smash v2 Buck Sneakers For Men    ₹499   \n",
       "99    BRUTON                                 Sneakers For Women    ₹329   \n",
       "\n",
       "   Discount  \n",
       "0   67% off  \n",
       "1    7% off  \n",
       "2   65% off  \n",
       "3   60% off  \n",
       "4   69% off  \n",
       "..      ...  \n",
       "95   7% off  \n",
       "96  71% off  \n",
       "97  20% off  \n",
       "98  85% off  \n",
       "99  74% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the above data\n",
    "df = pd.DataFrame({'Brand':Brand_Sneakers[:100],'Product_Desc':Product_Desc[:100],'Price':Price[:100],'Discount':Discount[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65663b9",
   "metadata": {},
   "source": [
    "# Q7-Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678b4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohit Gupta\\Desktop\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "936d6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17957382",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(4)\n",
    "\n",
    "#clicking on price filter\n",
    "price = driver.find_element(By.XPATH,\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "price.click()\n",
    "\n",
    "#clicking on black colour \n",
    "black = driver.find_element(By.XPATH,'//li[@class=\"colour-listItem\"]/label/div')\n",
    "black.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "637fb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the empty list\n",
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "\n",
    "#Scrapping the required details\n",
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,\"//div[@class='product-productMetaInfo']\")      \n",
    "    for i in brand_tags:\n",
    "        Brand.append(i.text)     \n",
    "        \n",
    "    Product_Desc_tags=driver.find_elements(By.XPATH,\"//div[@class='product-productMetaInfo']/h4[1]\")     \n",
    "    for i in Product_Desc_tags:\n",
    "        Product_Description.append(i.text)    \n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]') \n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text) \n",
    "        \n",
    "        nxt_button=driver.find_elements(By.XPATH,'//a[@rel=\"next\"]')\n",
    "\n",
    "try:\n",
    "    driver.get(nxt_button[1].get_attribute('href')) \n",
    "except:\n",
    "    driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a316ae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb5a2fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red Tape\\nMen Walking Shoes\\nRs. 1619Rs. 5399(...</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1619Rs. 5399(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roadster\\nMen Solid Running Shoes\\nRs. 1294Rs....</td>\n",
       "      <td>Men Solid Running Shoes</td>\n",
       "      <td>Rs. 1294Rs. 3699(65% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HRX by Hrithik Roshan\\nMen Aqua Shoes\\nRs. 779...</td>\n",
       "      <td>Men Aqua Shoes</td>\n",
       "      <td>Rs. 779Rs. 2599(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MENGLER\\nMen Walking Shoes\\nRs. 679Rs. 3999(83...</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 679Rs. 3999(83% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma\\nSoftride Rift Breeze\\nRs. 3249Rs. 6499(5...</td>\n",
       "      <td>Softride Rift Breeze</td>\n",
       "      <td>Rs. 3249Rs. 6499(50% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Monrow\\nWomen Sandals\\nRs. 1199Rs. 2299(Rs. 11...</td>\n",
       "      <td>Women Sandals</td>\n",
       "      <td>Rs. 1199Rs. 2299(Rs. 1100 OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma\\nMen Cell Vive Elevate Running\\nRs. 5199R...</td>\n",
       "      <td>Men Cell Vive Elevate Running</td>\n",
       "      <td>Rs. 5199Rs. 6499(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Red Tape\\nMen Walking Shoes\\nRs. 1559Rs. 5199(...</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1559Rs. 5199(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Mochi\\nWomen One Toe Flats\\nRs. 945Rs. 1890(50...</td>\n",
       "      <td>Women One Toe Flats</td>\n",
       "      <td>Rs. 945Rs. 1890(50% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PUMA Motorsport\\nMen SF Kart Cat Mid III\\nRs. ...</td>\n",
       "      <td>Men SF Kart Cat Mid III</td>\n",
       "      <td>Rs. 3574Rs. 6499(45% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Brand  \\\n",
       "0   Red Tape\\nMen Walking Shoes\\nRs. 1619Rs. 5399(...   \n",
       "1   Roadster\\nMen Solid Running Shoes\\nRs. 1294Rs....   \n",
       "2   HRX by Hrithik Roshan\\nMen Aqua Shoes\\nRs. 779...   \n",
       "3   MENGLER\\nMen Walking Shoes\\nRs. 679Rs. 3999(83...   \n",
       "4   Puma\\nSoftride Rift Breeze\\nRs. 3249Rs. 6499(5...   \n",
       "..                                                ...   \n",
       "95  Monrow\\nWomen Sandals\\nRs. 1199Rs. 2299(Rs. 11...   \n",
       "96  Puma\\nMen Cell Vive Elevate Running\\nRs. 5199R...   \n",
       "97  Red Tape\\nMen Walking Shoes\\nRs. 1559Rs. 5199(...   \n",
       "98  Mochi\\nWomen One Toe Flats\\nRs. 945Rs. 1890(50...   \n",
       "99  PUMA Motorsport\\nMen SF Kart Cat Mid III\\nRs. ...   \n",
       "\n",
       "                     Product_Desc                           Price  \n",
       "0               Men Walking Shoes       Rs. 1619Rs. 5399(70% OFF)  \n",
       "1         Men Solid Running Shoes       Rs. 1294Rs. 3699(65% OFF)  \n",
       "2                  Men Aqua Shoes        Rs. 779Rs. 2599(70% OFF)  \n",
       "3               Men Walking Shoes        Rs. 679Rs. 3999(83% OFF)  \n",
       "4            Softride Rift Breeze       Rs. 3249Rs. 6499(50% OFF)  \n",
       "..                            ...                             ...  \n",
       "95                  Women Sandals  Rs. 1199Rs. 2299(Rs. 1100 OFF)  \n",
       "96  Men Cell Vive Elevate Running       Rs. 5199Rs. 6499(20% OFF)  \n",
       "97              Men Walking Shoes       Rs. 1559Rs. 5199(70% OFF)  \n",
       "98            Women One Toe Flats        Rs. 945Rs. 1890(50% OFF)  \n",
       "99        Men SF Kart Cat Mid III       Rs. 3574Rs. 6499(45% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the above data\n",
    "df = pd.DataFrame({'Brand':Brand[:100],'Product_Desc':Product_Description[:100],'Price':Price[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef25fd",
   "metadata": {},
   "source": [
    "# Q8-Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15d94ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohit Gupta\\Desktop\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66d67662",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "171ee91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "nation.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f0572b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu1=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[5]/li[11]\")\n",
    "cpu1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e647faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "262e8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    Title.append(i.text)\n",
    "\n",
    "ratings_tag=driver.find_elements(By.XPATH,'//a[@class=\"a-popover-trigger a-declarative\"]')\n",
    "for i in ratings_tag[0:10]:\n",
    "    Ratings.append(i.text)    \n",
    "\n",
    "    price_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tag[0:10]:\n",
    "    Price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29e2bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d84b71c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_list</th>\n",
       "      <th>Rating_list</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Aspire 3 Laptop AMD 3020e Dual-Core Proce...</td>\n",
       "      <td></td>\n",
       "      <td>24,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i5 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>55,008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6...</td>\n",
       "      <td></td>\n",
       "      <td>21,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...</td>\n",
       "      <td></td>\n",
       "      <td>25,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6...</td>\n",
       "      <td></td>\n",
       "      <td>29,374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i5 11th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>33,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell Latitude E5470 Intel Core i5 6t...</td>\n",
       "      <td></td>\n",
       "      <td>44,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" ...</td>\n",
       "      <td></td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP 14s, 12th Gen Intel Core i5 16GB RAM/512GB ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 14s, 5th Gen AMD Ryzen 3- 8GB RAM/512GB SSD...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title_list Rating_list job_location\n",
       "0  Acer Aspire 3 Laptop AMD 3020e Dual-Core Proce...                   24,990\n",
       "1  Lenovo IdeaPad Slim 3 Intel Core i5 12th Gen 1...                   55,008\n",
       "2  Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6...                   21,513\n",
       "3  ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...                   25,990\n",
       "4  Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6...                   29,374\n",
       "5  Lenovo IdeaPad Slim 5 Intel Core i5 11th Gen 1...                   33,990\n",
       "6  (Renewed) Dell Latitude E5470 Intel Core i5 6t...                   44,999\n",
       "7  Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" ...                   59,990\n",
       "8  HP 14s, 12th Gen Intel Core i5 16GB RAM/512GB ...                         \n",
       "9  HP 14s, 5th Gen AMD Ryzen 3- 8GB RAM/512GB SSD...                         "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the data frame from above data\n",
    "df=pd.DataFrame({'Title_list':Title,'Rating_list':Ratings,'job_location':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a758a36",
   "metadata": {},
   "source": [
    "# Q9-Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "59dcfc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohit Gupta\\Desktop\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ff14fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7674a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "designation.send_keys('Data Scientist')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "22f79b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=105.0.5195.125)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x005EDF13+2219795]\n\tOrdinal0 [0x00582841+1779777]\n\tOrdinal0 [0x00494100+803072]\n\tOrdinal0 [0x004BE523+976163]\n\tOrdinal0 [0x004BDB93+973715]\n\tOrdinal0 [0x004DE7FC+1107964]\n\tOrdinal0 [0x004B94B4+955572]\n\tOrdinal0 [0x004DEA14+1108500]\n\tOrdinal0 [0x004EF192+1175954]\n\tOrdinal0 [0x004DE616+1107478]\n\tOrdinal0 [0x004B7F89+950153]\n\tOrdinal0 [0x004B8F56+954198]\n\tGetHandleVerifier [0x008E2CB2+3040210]\n\tGetHandleVerifier [0x008D2BB4+2974420]\n\tGetHandleVerifier [0x00686A0A+565546]\n\tGetHandleVerifier [0x00685680+560544]\n\tOrdinal0 [0x00589A5C+1808988]\n\tOrdinal0 [0x0058E3A8+1827752]\n\tOrdinal0 [0x0058E495+1827989]\n\tOrdinal0 [0x005980A4+1867940]\n\tBaseThreadInitThunk [0x76AC6739+25]\n\tRtlGetFullPathName_UEx [0x773390AF+1215]\n\tRtlGetFullPathName_UEx [0x7733907D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ROHITG~1\\AppData\\Local\\Temp/ipykernel_3312/2667115699.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Noida'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36msend_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremote_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         self._execute(Command.SEND_KEYS_TO_ELEMENT,\n\u001b[0m\u001b[0;32m    224\u001b[0m                       {'text': \"\".join(keys_to_typing(value)),\n\u001b[0;32m    225\u001b[0m                        'value': keys_to_typing(value)})\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    430\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=105.0.5195.125)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x005EDF13+2219795]\n\tOrdinal0 [0x00582841+1779777]\n\tOrdinal0 [0x00494100+803072]\n\tOrdinal0 [0x004BE523+976163]\n\tOrdinal0 [0x004BDB93+973715]\n\tOrdinal0 [0x004DE7FC+1107964]\n\tOrdinal0 [0x004B94B4+955572]\n\tOrdinal0 [0x004DEA14+1108500]\n\tOrdinal0 [0x004EF192+1175954]\n\tOrdinal0 [0x004DE616+1107478]\n\tOrdinal0 [0x004B7F89+950153]\n\tOrdinal0 [0x004B8F56+954198]\n\tGetHandleVerifier [0x008E2CB2+3040210]\n\tGetHandleVerifier [0x008D2BB4+2974420]\n\tGetHandleVerifier [0x00686A0A+565546]\n\tGetHandleVerifier [0x00685680+560544]\n\tOrdinal0 [0x00589A5C+1808988]\n\tOrdinal0 [0x0058E3A8+1827752]\n\tOrdinal0 [0x0058E495+1827989]\n\tOrdinal0 [0x005980A4+1867940]\n\tBaseThreadInitThunk [0x76AC6739+25]\n\tRtlGetFullPathName_UEx [0x773390AF+1215]\n\tRtlGetFullPathName_UEx [0x7733907D+1165]\n"
     ]
    }
   ],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "location.send_keys('Noida') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6bd83d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "job=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69fb758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "jobs=driver.find_elements(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[2]')\n",
    "for i in jobs[0:10]:\n",
    "    jobs=i.text\n",
    "    job.append(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f22eb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist\\nIBM India Pvt. Limited\\n · \\n4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               data0\n",
       "0  Data Scientist\\nIBM India Pvt. Limited\\n · \\n4..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame({'data0':job})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e66c0",
   "metadata": {},
   "source": [
    "# Q10-Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cafd53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohit Gupta\\Desktop\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f992c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35638ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = driver.find_element(By.XPATH,\"/html/body/div/div/div/div[1]/header/nav/ul/li[3]\")\n",
    "salaries.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7afae2d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\"}\n  (Session info: chrome=105.0.5195.125)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x005EDF13+2219795]\n\tOrdinal0 [0x00582841+1779777]\n\tOrdinal0 [0x0049423D+803389]\n\tOrdinal0 [0x004C3025+995365]\n\tOrdinal0 [0x004C31EB+995819]\n\tOrdinal0 [0x004F0F52+1183570]\n\tOrdinal0 [0x004DE844+1108036]\n\tOrdinal0 [0x004EF192+1175954]\n\tOrdinal0 [0x004DE616+1107478]\n\tOrdinal0 [0x004B7F89+950153]\n\tOrdinal0 [0x004B8F56+954198]\n\tGetHandleVerifier [0x008E2CB2+3040210]\n\tGetHandleVerifier [0x008D2BB4+2974420]\n\tGetHandleVerifier [0x00686A0A+565546]\n\tGetHandleVerifier [0x00685680+560544]\n\tOrdinal0 [0x00589A5C+1808988]\n\tOrdinal0 [0x0058E3A8+1827752]\n\tOrdinal0 [0x0058E495+1827989]\n\tOrdinal0 [0x005980A4+1867940]\n\tBaseThreadInitThunk [0x76AC6739+25]\n\tRtlGetFullPathName_UEx [0x773390AF+1215]\n\tRtlGetFullPathName_UEx [0x7733907D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ROHITG~1\\AppData\\Local\\Temp/ipykernel_3312/1238493639.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_scince\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_scince\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Scientist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    853\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    856\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    430\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\"}\n  (Session info: chrome=105.0.5195.125)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x005EDF13+2219795]\n\tOrdinal0 [0x00582841+1779777]\n\tOrdinal0 [0x0049423D+803389]\n\tOrdinal0 [0x004C3025+995365]\n\tOrdinal0 [0x004C31EB+995819]\n\tOrdinal0 [0x004F0F52+1183570]\n\tOrdinal0 [0x004DE844+1108036]\n\tOrdinal0 [0x004EF192+1175954]\n\tOrdinal0 [0x004DE616+1107478]\n\tOrdinal0 [0x004B7F89+950153]\n\tOrdinal0 [0x004B8F56+954198]\n\tGetHandleVerifier [0x008E2CB2+3040210]\n\tGetHandleVerifier [0x008D2BB4+2974420]\n\tGetHandleVerifier [0x00686A0A+565546]\n\tGetHandleVerifier [0x00685680+560544]\n\tOrdinal0 [0x00589A5C+1808988]\n\tOrdinal0 [0x0058E3A8+1827752]\n\tOrdinal0 [0x0058E495+1827989]\n\tOrdinal0 [0x005980A4+1867940]\n\tBaseThreadInitThunk [0x76AC6739+25]\n\tRtlGetFullPathName_UEx [0x773390AF+1215]\n\tRtlGetFullPathName_UEx [0x7733907D+1165]\n"
     ]
    }
   ],
   "source": [
    "data_scince = driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "data_scince.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59c574e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name=[]\n",
    "total_salary=[]\n",
    "avg_salary=[]\n",
    "mini_salary=[]\n",
    "max_salary=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bbeb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company name from the given page\n",
    "com=driver.find_elements(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]\")\n",
    "for i in com[0:10]:\n",
    "    com=i.text\n",
    "    company_name.append(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ce3f199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10 results are available, use up and down arrow keys to navigate.\\nSoftware Engineer\\nSoftware Developer\\nSystem Engineer\\nSenior Software Engineer\\nProcess Associate\\nSales Executive\\nAssociate Consultant\\nSenior Associate\\nAnalyst\\nSoftwaretest Engineer\\nSenior Analyst\\nSenior Systems Engineer\\nSales Officer\\nProgrammer Analyst\\nRelationship Manager\\nCustomer Service Executiv...\\nTest Engineer\\nDeputy Manager\\nCustomer Care Executive\\nProject Engineer\\nCompany Name\\nAverage Salary\\nGoogle\\nSoftware Engineer Salary\\n1-4 yrs experience (based on 58 salaries)\\n₹ 35.5L\\n₹ 12.7L\\n₹ 97.0L\\nMicrosoft Corporation\\nSoftware Engineer Salary\\n1-4 yrs experience (based on 344 salaries)\\n₹ 23.7L\\n₹ 13.0L\\n₹ 50.0L\\nGoldman Sachs\\nSoftware Engineer Salary\\n1-2 yrs experience (based on 36 salaries)\\n₹ 22.9L\\n₹ 12.0L\\n₹ 34.0L\\nArista Networks\\nSoftware Engineer Salary\\n1-4 yrs experience (based on 51 salaries)\\n₹ 22.3L\\n₹ 5.0L\\n₹ 38.0L\\nTekion\\nSoftware Engineer Salary\\n2-4 yrs experience (based on 50 salaries)\\n₹ 21.9L\\n₹ 11.7L\\n₹ 38.0L\\nAmazon\\nSoftware Engineer Salary\\n1-4 yrs experience (based on 141 salaries)\\n₹ 21.2L\\n₹ 8.7L\\n₹ 45.0L\\nServicenow Software Development India\\nSoftware Engineer Salary\\n2-4 yrs experience (based on 79 salaries)\\n₹ 21.1L\\n₹ 14.0L\\n₹ 32.0L\\nWalmart\\nSoftware Engineer Salary\\n1-4 yrs experience (based on 110 salaries)\\n₹ 20.2L\\n₹ 12.0L\\n₹ 32.5L\\nPayPal\\nSoftware Engineer Salary\\n1-2 yrs experience (based on 29 salaries)\\n₹ 19.6L\\n₹ 12.0L\\n₹ 30.0L\\nArcesium\\nSoftware Engineer Salary\\n1-2 yrs experience (based on 69 salaries)\\n₹ 19.5L\\n₹ 12.0L\\n₹ 34.0L']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8d234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
